server:
  addr: ":8080"
  read_timeout_sec: 15
  write_timeout_sec: 15
  idle_timeout_sec: 60
  shutdown_timeout_sec: 10
  rate_limit:
    enabled: true
    requests_per_minute: 120 # Global rate limit
    burst: 20 # Allow short bursts
  cors:
    allow_origins: ["*"] # em prod: ["https://app.seudominio.com"]
    allow_methods: ["GET", "POST", "PUT", "DELETE"]
    allow_headers: ["Content-Type", "Authorization"]
    allow_credentials: true
    max_age: 600

defaults:
  max_tokens: 2048
  temperature: 0.7
  top_p: 0.9
  frequency_penalty: 0.0
  presence_penalty: 0.0
  stream: false
  timeout_sec: 30
  tenant_id: "default"
  user_id: "anonymous"

providers:
  openai:
    type: openai
    base_url: https://api.openai.com
    key_env: OPENAI_API_KEY
    default_model: gpt-4o-mini

  gemini:
    type: gemini
    base_url: https://generativelanguage.googleapis.com
    key_env: GEMINI_API_KEY
    default_model: gemini-2.5-flash

  anthropic:
    type: anthropic
    base_url: https://api.anthropic.com
    key_env: ANTHROPIC_API_KEY
    default_model: claude-3-5-sonnet-20241022

  groq:
    type: groq
    base_url: https://api.groq.com
    key_env: GROQ_API_KEY
    default_model: llama-3.1-70b-versatile

  # Future providers (uncomment when implemented)
  # openrouter:
  #   type: openrouter
  #   base_url: https://openrouter.ai/api
  #   key_env: OPENROUTER_API_KEY
  #   default_model: google/gemini-flash-1.5

  # ollama:
  #   type: ollama
  #   base_url: http://localhost:11434
  #   key_env: ""
  #   default_model: llama3.1
